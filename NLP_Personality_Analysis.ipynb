{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "575589a6-8c41-48f5-bf63-f2ddf70a31fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6510 entries, 0 to 6509\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Speaker_1    6510 non-null   object\n",
      " 1   Speaker_2    6510 non-null   object\n",
      " 2   Personality  6510 non-null   object\n",
      " 3   Utterance_1  6510 non-null   object\n",
      " 4   Utterance_2  6510 non-null   object\n",
      " 5   Utterance_3  6510 non-null   object\n",
      " 6   Emotion_1    6510 non-null   object\n",
      " 7   Emotion_2    6510 non-null   object\n",
      " 8   Emotion_3    6510 non-null   object\n",
      " 9   Sentiment_1  6510 non-null   object\n",
      " 10  Sentiment_2  6510 non-null   object\n",
      " 11  Sentiment_3  6510 non-null   object\n",
      "dtypes: object(12)\n",
      "memory usage: 610.4+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_raw = pd.read_csv('Dyadic_PELD.tsv', sep='\\t', header=0)\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a56149-942e-4322-92d6-aaf62869db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "confirmation_words = ['yes', 'yeah', 'okay', 'sure']\n",
    "negation_words = ['no', 'not', 'never', 'nope']\n",
    "\n",
    "speakers = df.groupby('Speaker_1').apply(analyze_speaker).apply(pd.Series)\n",
    "\n",
    "# Function to analyze speaker data\n",
    "def analyze_speaker(speaker_df):\n",
    "    utterances = speaker_df[['Utterance_1', 'Utterance_2', 'Utterance_3']].values.flatten()\n",
    "    combined_text = ' '.join(utterances)\n",
    "    \n",
    "    # Tokenize words\n",
    "    words = combined_text.split()\n",
    "    word_count = len(words)\n",
    "    \n",
    "    # Vocabulary analysis\n",
    "    word_freq = Counter(words)\n",
    "    vocab_size = len(word_freq)\n",
    "    vocab_set = set(word_freq.keys())\n",
    "    \n",
    "    # Count repeated words (words that appear more than once)\n",
    "    repetitions = sum([count-1 for count in word_freq.values() if count > 1])\n",
    "    \n",
    "    # Count confirmation and negation words\n",
    "    confirmation_count = sum([word_freq[word] for word in confirmation_words if word in word_freq])\n",
    "    negation_count = sum([word_freq[word] for word in negation_words if word in word_freq])\n",
    "    \n",
    "    return {\n",
    "        'Total_Utterances': len(utterances),\n",
    "        'Total_Words': word_count,\n",
    "        'Vocabulary_Size': vocab_size,\n",
    "        'Vocabulary_Set': vocab_set,\n",
    "        'Repetitions': repetitions,\n",
    "        'Confirmation_Count': confirmation_count,\n",
    "        'Negation_Count': negation_count\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
